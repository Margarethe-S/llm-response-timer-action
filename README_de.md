# üìú llm-response-timer-action
> ‚û°Ô∏è [Hier geht‚Äôs zur englischen Version](README.md)

Diese GitHub Action testet ein lokal laufendes Sprachmodell √ºber LM Studio, indem sie eine promptbasierte Anfrage sendet, die Antwortzeit misst und bei Abschluss ein akustisches Feedback ausgibt.

## üîó Einsatz in Dr. Nature

Diese GitHub Action wurde urspr√ºnglich im Rahmen des Projekts [Dr. Nature](https://github.com/Margarethe-Techstarter/dr-nature) entwickelt ‚Äì einer lokalen KI-Anwendung zur Beantwortung naturheilkundlicher Gesundheitsfragen.

‚û°Ô∏è Zum Hauptprojekt: **[Dr. Nature ‚Äì A holistic AI-powered health assistant](https://github.com/Margarethe-Techstarter/dr-nature)**

## üìä Dieses Projekt befindet sich aktuell in aktiver Entwicklung.

Obwohl die Action noch nicht im GitHub Marketplace ver√∂ffentlicht wurde, wird sie bereits von Entwickler*innen getestet und weiterverfolgt.  
Das zeigt: Die Idee trifft auf Interesse ‚Äì und der Ansatz ist praxisrelevant.

Die Entwicklung erfolgt bewusst offen, lernorientiert und dokumentiert ‚Äì inklusive aller Tests, Fehlerphasen und Verbesserungen.  
Der Fokus liegt auf Stabilit√§t, Klarheit und echter Weiterentwicklung, nicht auf Perfektion.

üõ†Ô∏è Eine Ver√∂ffentlichung im Marketplace ist geplant, sobald die Funktionalit√§t verl√§sslich sichergestellt ist.


## ‚úÖ Funktionen

- L√§dt die `.env`-Datei, um die LM Studio API-URL zu erhalten
- L√§dt ein Systemprompt aus einer lokalen `.txt`-Datei
- Sendet einen Prompt per HTTP POST (JSON) an ein lokal laufendes Sprachmodell
- Misst die genaue Antwortzeit in Sekunden und Minuten
- Spielt einen **Erfolgston**, wenn eine Antwort empfangen wurde
- Spielt einen **Warnton**, wenn ein Timeout oder Fehler auftritt
- Unterscheidet zwischen:
  - ‚è∞ Zeit√ºberschreitung (nach 300 Sekunden)
  - ‚ùå Verbindungs- oder Anfragefehler
  - ‚ùå JSON- oder Schl√ºsselverarbeitungsfehler

---

## üìÅ Logs

Alle Ergebnisse werden gespeichert unter:  
`/logs`

Nach jedem Durchlauf erstellt das Skript eine Log-Datei im Ordner `logs/.txt`.  
Jeder Eintrag enth√§lt:

- Den verwendeten Prompt-Pfad
- Die gestellte Nutzerfrage
- Die vollst√§ndige Antwort oder eine Fehlermeldung
- Die ben√∂tigte Zeit
- Eine Statusmeldung (‚Äû‚úÖ Erfolgreich‚Äú oder Details zum Fehler)


## üß™ Ideal geeignet f√ºr

- Testen der Antwortzeit lokal laufender Sprachmodelle
- Debugging von Systemprompts
- Automatisierung deines KI-Entwicklungs-Workflows


## üìÇ Beispiel-Prompt-Datei

Speichere deinen Prompt zum Beispiel in:
`prompts/action_promt1.0.txt`

Du kannst den Pfad in der `main.py` anpassen ‚Äì direkt √ºber die Variable `prompt_path`.

## üõ†Ô∏è Installation

```bash
pip install -r requirements.txt
```

## ‚ñ∂Ô∏è Aktion lokal ausf√ºhren

```bash
python main.py
```
Das Skript f√ºhrt dann folgende Schritte aus:
- L√§dt Umgebungsvariablen und den Systemprompt
- Sendet eine Beispiel-Nutzerfrage
- Misst die Antwortzeit
- Gibt die Antwort des Modells im Terminal aus
- Spielt einen Systemton ab
- Speichert das Ergebnis im /logs-Ordner


## üñºÔ∏è Screenshots 
Screenshot: Log-Ordnerstrucktur

![alt text](images/image-1.png)

Screenshot: Beispiel-Inhalt einer Log-Datei

![alt text](images/image.png)

Screenshot: Terminalausgabe der Antwortzeit

![alt text](images/image-2.png)

---
## üîì Frei verwendbar

Dieses Repository wird im Sinne von Lernen und Weiterentwicklung bereitgestellt.  
Gerne darfst du es forken oder anpassen, wenn es dir bei eigenen Projekten hilft.

Viel Erfolg bei deinen Entwicklungen!

üìù Lizenz: Dieses Projekt steht unter der MIT-Lizenz.  
Details findest du in der Datei [LICENSE](./LICENSE).

---
 
> ‚ö†Ô∏è **Hinweis**  
> Diese GitHub Action wurde bisher erfolgreich mit einem lokal laufenden Modell √ºber **LM Studio** getestet (z.‚ÄØB. *Mistral 7B*).  
> Andere Modelle k√∂nnten ebenfalls funktionieren, wurden jedoch **noch nicht getestet**.
